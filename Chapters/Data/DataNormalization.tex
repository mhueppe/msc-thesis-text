\section{Details Parsing}\label{sec:data_normalization}
\begin{table}[h!]
	\centering
	\begin{tabularx}{\linewidth}{lX}
		\toprule
		\texttt{entry\_id} & \texttt{pdbx\_details}\\
		\midrule
		\href{https://www.rcsb.org/structure/3P4H}{3P4H} & Crystallization was carried out in sitting-drop vapor-diffusion setups with 1:1 mixtures of protein solution containing 0.7 mM Cko and 1.8 mM MnCl2 and reservoir solution containing 20\% PEG 3350 and 0.2 M Na2HPO4 , pH 9.5, VAPOR DIFFUSION, SITTING DROP, temperature 298K
		\\
		\href{https://www.rcsb.org/structure/3P4V}{3P4V} & 3.2M (NH4)2SO4, 0.1M Glycine, pH 9.5, VAPOR DIFFUSION, HANGING DROP, temperature 289K \\
		\href{https://www.rcsb.org/structure/3P62}{3P62} & 100mM sodium cacodylate, 100 mM sodium acetate, 16-18\% isopropanol, pH 6.2, VAPOR DIFFUSION, SITTING DROP, temperature 293K \\
		\href{https://www.rcsb.org/structure/3PCA}{3PCA} & pH 8.4 \\
		\href{https://www.rcsb.org/structure/6LJR}{6LJR} & PEG \\
		\href{https://www.rcsb.org/structure/3PF1}{3PF1} & 15-17\% PEG 4K 0.2M KCl, protein dialysed in 10mM NaOAc 50mM NaCl, 10\% glycerol 0.4\%C8E4, pH 5.5, VAPOR DIFFUSION, HANGING DROP, temperature 295K
		\\
		\bottomrule
	\end{tabularx}	
	\caption{Examples of free text descriptions of crystallization conditions given in the \gls{pdb}}
	\label{tab:detailsExamples}
\end{table}

The examples in \autoref{tab:detailsExamples} illustrate the complexity involved in parsing protein crystallization conditions from free text into a uniform, machine-readable chemical cocktail representation. The first entry (3P4H) demonstrates that crystallization conditions are often embedded in long, narrative-style descriptions that mix experimental setup, protein concentration, co-factors, and reservoir composition in a single sentence. Extracting a structured cocktail from such text requires an algorithm that can reliably identify and segment chemically relevant entities (salts, buffers, precipitants, additives) and distinguish them from procedural information.

The second entry (3P4V) highlights the lack of uniformity in how units and concentrations are reported. Here, components are given in varying molar units, whereas other entries in the table use percentages. A robust parsing pipeline must therefore handle multiple concentration formats, convert them into a common representation. The third entry (3P62) further emphasizes semantic heterogeneity in naming: chemicals may be referred to by systematic names (e.g. “sodium cacodylate”, “sodium acetate”) rather than by their chemical formulas, in contrast to entries that use formula-based names (e.g. MnCl\textsubscript{2}, Na\textsubscript{2}HPO\textsubscript{4}). \textcite{Peat2005} illustrated the difference in naming conventions by showing the 30 different ways ammonium sulfate is spelled in the dataset. This necessitates normalization against a chemical dictionary or ontology to map synonymic names and formulas to a shared canonical identifier.

Entry 6LJR and 3PCA illustrates that some \texttt{pdbx\_details} fields contain only minimal useful information. Such cases require the parser to handle incomplete cocktails and to distinguish between genuinely missing data and conditions that were simply not reported. The variability in reporting detail is substantial: while the average description length is 93 characters (SD = 72), the lengths range from as little as a single character to as much as 1758 characters. This large spread underscores the heterogeneity and inconsistency in the level of detail provided across entries. 

Finally, the entry 3PF1 illustrates more subtle challenges, including the presence of concentration ranges, ambiguous abbreviations (PEG 4K instead of PEG 4000), and incomplete specifications (e.g. “\%” without an explicit indication of whether it is w/v or v/v). Additionally, the same text string can interleave multiple components without clear delimiters, making tokenization and assignment of units to the correct solute non-trivial. These examples underscore that converting free-text crystallization descriptions into uniform chemical cocktails is not a simple extraction task, but a complex natural language processing and normalization problem that must account for heterogeneous syntax, inconsistent units, synonymic naming, incomplete information, and domain-specific ambiguities.



\subsection{Pipeline}
\textcite{Lynch2020} constructed a multi-stage extraction pipeline designed to transform the unstructured crystallization metadata contained in the \gls{pdb}
into a consistent format. The goal of their proposed workflow as to impose a controlled vocabulary on the free text description and thereby enable large-scale analyses of crystallization conditions. The complete procedure consists of the four major steps 1. data acquisition, 2. details parsing and text normalization, 3. curating a compound dictionary to create a controlled vocabulary, and finally 4. the construction of the crystallization details dataset. In the following, the focus is on the second and third step as they are of importance for this project and also where most additions have been made. 

\subsubsection{Details Parsing}
The address the variation in wording, punctuation, spelling and chemical names \citet{Lynch2020} designed a custom parsing function that performs multiple passes over the raw text. This function extracts: chemical component names, their reported concentrations (if present) and incubation temperatures as well as pH level. The parser explicitly handles inconsistent spacing, punctuation typographical errors and irregular phrasing that commonly appear in the deposited records. 

\subsubsection{Controlled Vocabulary}
A central element of the pipeline is manually curated compound dictionary used to standardize chemical identities. The authors compiled a list of 312 unique compounds, created by: 
\begin{enumerate}
	\item Starting with the most frequently occuring chemical names in the PDB scrape
	\item Manually merging synonym, variant spellings, and abbreviations and
	\item Expanding the dictionary through iterative refinement
\end{enumerate}

The system also includes a mechanism to extend the dictionary as new, rare or previously unseen chemicals appear in the updated \gls{pdb}. 

\subsection{Parsing Quality}
However, the parsing was not perfect in that it identified words as chemicals even though they were not. Originally, the parsing resulting in the majority of chemicals being parsed being present only once. This resulted in a total unique chemical count of around 30 000. This can be seen in \autoref{fig:numberOfOccurencesPerChemical}. 
The first one was to do a manual screening of words that were often parsed as chemicals but are not. This included for example the token "crystal tracking id" with the id typically being picked up as the concentration. This removed around 350 of the faulty chemical names. Similarly, sometimes verbs were also identified as proteins. Using Spacy all chemicals that only occured once were screened. After confirming that the language model can distinguish between chemical names and Verbs were removed. This got rid of around 1400 false chemicals.  

However, some examples were just too broken too unique to be added to the parsing pipeline. An example is 8C9L for which the entered description is "'0.1MBis Tris Propane pH 6.50.02 MSodium potassium phosphate pH 7.520 \% w/vPEG 335010\% v/vEthylene glycol'". Here the problem is that after each numerical value a space is missing not being clear if a pH of 7.5 is meant. 

PH and temperature values were sometimes provided in the free-text field but not in the corresponding numerical fields. After extracting and parsing pH and temperature from the free text, the proportion of missing values decreased to 9.2\% for pH and 8.3\% for temperature.

\begin{figure}[h!]
	\centering		
	\begin{subfigure}{0.35\linewidth}
		\centering
		\includegraphics[width=\linewidth]{../msc-thesis-code/data/dataExploration/plots/occurencesDistribution}
		\label{fig:numberOfOccurencesPerChemical}
	\end{subfigure}
	\begin{subfigure}[b]{0.64\linewidth}
		\centering
		\includegraphics[width=\linewidth]{../msc-thesis-code/data/dataExploration/plots/coverageByThreshold}
		\label{fig:coverageVsNumberOfChemicals}
	\end{subfigure}
	\caption{The number of occurrences for chemicals and the coverage of the dataset for different chemical dictionary sizes}
	\label{fig:numberAndOccurences}
\end{figure}



\begin{figure}[h!]
	\centering		
	\begin{subfigure}{0.495\linewidth}
		\centering
		\includegraphics[width=\linewidth]{../msc-thesis-code/data/dataExploration/plots/phGivenVsParsedpH}
		\label{fig:enteredVsParsedPh}
	\end{subfigure}
	\begin{subfigure}[b]{0.495\linewidth}
		\centering
		\includegraphics[width=\linewidth]{../msc-thesis-code/data/dataExploration/plots/tempGivenVsParsedTemp}
		\label{fig:enteredVsParsedTemp}
	\end{subfigure}
	\caption{Temperature and pH values entered in numerical field vs. parsed from free text}
	\label{fig:enteredVsParsed}
\end{figure}
